{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Programming ex04: Keras Feed Forward NNs\n",
    "\n",
    "Welcome to the fourth assignment. In this assignment, you will:\n",
    "1. Learn to use Keras, a high-level neural networks API (programming framework), written in Python and capable of running on top of several lower-level frameworks including TensorFlow and CNTK. \n",
    "2. See how you can build a deep learning model in a very short time. \n",
    "\n",
    "Why are we using Keras? Keras was developed to enable building and experimenting with different models very quickly. Just as TensorFlow is a higher-level API than CUDA and numpy, Keras is an even higher-level framework that provides additional abstractions. Being able to go from idea to result with the least possible delay is key to finding good models. However, Keras is more restrictive than the lower-level frameworks, so there are some complex models that you can implement in TensorFlow but not (or at least not with added difficulty) in Keras. That being said, Keras will work fine for many common tasks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important: Additional Packages Required!\n",
    "\n",
    "Please activate your virtual environment and install the updated requirements.txt (or requirements_windows.txt)\n",
    "using pip3 or the import statements in the cell below will fail.\n",
    "\n",
    "\n",
    "### Optional:\n",
    "If you have a compatible Nvidia GPU, you can replace the \"tensorflow\" package with \"tensorflow-gpu\". \n",
    "This requires CUDA drivers to be installed on your machine and can get messy. But the speed-up is huge!\n",
    "\n",
    "*Do this only if you know what you're doing and if you feel comfortable repairing your system on a shell without Xorg running. We can not provide any support. * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.models import Model\n",
    "from utils.data_utils import load_CIFAR10\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We will use the same dataset as previous assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3072)\n",
      "Train labels shape:  (49000, 10)\n",
      "Validation data shape:  (1000, 3072)\n",
      "Validation labels shape:  (1000, 10)\n",
      "Test data shape:  (1000, 3072)\n",
      "Test labels shape:  (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = '../../data/cifar/'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    X_train /= 255\n",
    "    X_val /= 255\n",
    "    X_test /= 255\n",
    "    X_dev /= 255\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Building a model in Keras\n",
    "\n",
    "Keras is very good for rapid prototyping. In just a short time you will be able to build a model that achieves outstanding results.\n",
    "\n",
    "Here is an example of a model in Keras:\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "def create_awesome_model(input_shape,num_classes):    \n",
    "    \n",
    "    # The next line defines an input placeholder of shape \"input_shape\"\n",
    "    # for the data you'll feed to the model.\n",
    "    # Depending on the backend, this will be automatically pushed to \n",
    "    # available CPUs/GPUs!\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    # Now we define a fully connected layer of 64 neurons with a RELU \n",
    "    # activation function that receives the previously defined placeholder as an input. \n",
    "    # Note the slightly unusual syntax of FUNCTION_NAME(hyperparameters)(input)\n",
    "    # Again, all required operations are mapped to appropriate computing \n",
    "    # resources on your machine.\n",
    "    X = Dense(64, activation='relu')(X_input) \n",
    "    \n",
    "    # Adding a softmax classifier on top.\n",
    "    X = Dense(num_classes, activation='softmax', name='fc')(X)\n",
    "\n",
    "    # This creates a Keras model instance.\n",
    "    # This is an abstraction of the entire chain of layers that you\n",
    "    # just stacked on top of each other and allows to conveniently\n",
    "    # handle training, testing and predicting.\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "    return model\n",
    "```\n",
    "\n",
    "It is perfectly fine to reassign new layers to the `X` variable in the code above, as each layer/operation stores references to what it takes as an input. Just note that you need to keep an explicit reference to the `X_input` variable,\n",
    "as you need to pass it to the `Model()` function in the end.\n",
    "\n",
    "Have a look at the API documentation:\n",
    "- https://keras.io/getting-started/functional-api-guide/\n",
    "- https://keras.io/layers/core/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Four Layer Neural Network in Keras [5pt]\n",
    "\n",
    "Implement a `FourLayerNN()` model with the following structure:\n",
    "- input layer\n",
    "- fully-connected layer\n",
    "- fully-connected layer\n",
    "- output layer. \n",
    "\n",
    "Feel free to play with the number of neurons in the hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FourLayerNN(input_shape, num_classes):\n",
    "    #############################################################################\n",
    "    # TODO: Complete a simple 4 layer neural network                            #\n",
    "    #############################################################################\n",
    "    X_input = Input(input_shape)\n",
    "    x = Dense(64, activation='relu')(X_input)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs = X_input, outputs = x)\n",
    "\n",
    "    #############################################################################\n",
    "    #                         END OF YOUR CODE                                  #\n",
    "    #############################################################################\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Workflow\n",
    "\n",
    "You have now built a function that assembles your model. To train and test this model, there are four steps in Keras:\n",
    "\n",
    "\n",
    "1. Create the model by calling the `FourLayerNN()` function\n",
    "2. Compile the model by calling \n",
    "    - `model.compile()`\n",
    "3. Train the model on train data by calling \n",
    "    - `model.fit()`\n",
    "4. Test the model on test data by calling `model.evaluate()`\n",
    "\n",
    "To find out what arguments the `model.compile()`, `model.fit()`, `model.evaluate()` take, refer to the official [Keras documentation](https://keras.io/models/model/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Initialize and compile the model [4pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "model = None\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "# TODO: initialize and compile the model                                    #\n",
    "# Choose the \"categorial crossentropy loss\" and add \"accuracy\" as a metric! #\n",
    "# Choose the other required arguments of compile() wisely, they influence   #\n",
    "# your models performance.                                                  #\n",
    "#############################################################################\n",
    "input_shape = X_train[0].shape\n",
    "model = FourLayerNN(input_shape,num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#############################################################################\n",
    "#                         END OF YOUR CODE                                  #\n",
    "#############################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Train the model: [3pt]\n",
    "\n",
    "Note that if you run `fit()` again, the `model` will continue to train with the parameters it has already learnt instead of reinitializing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "49000/49000 [==============================] - 4s 90us/step - loss: 1.6738 - acc: 0.4076 - val_loss: 1.5488 - val_acc: 0.4520\n",
      "Epoch 2/20\n",
      "49000/49000 [==============================] - 4s 86us/step - loss: 1.4826 - acc: 0.4777 - val_loss: 1.4504 - val_acc: 0.4850\n",
      "Epoch 3/20\n",
      "49000/49000 [==============================] - 4s 86us/step - loss: 1.3966 - acc: 0.5090 - val_loss: 1.4229 - val_acc: 0.4910\n",
      "Epoch 4/20\n",
      "49000/49000 [==============================] - 4s 87us/step - loss: 1.3356 - acc: 0.5295 - val_loss: 1.4131 - val_acc: 0.4960\n",
      "Epoch 5/20\n",
      "49000/49000 [==============================] - 5s 92us/step - loss: 1.2894 - acc: 0.5456 - val_loss: 1.4265 - val_acc: 0.5160\n",
      "Epoch 6/20\n",
      "49000/49000 [==============================] - 5s 96us/step - loss: 1.2510 - acc: 0.5578 - val_loss: 1.3887 - val_acc: 0.5190\n",
      "Epoch 7/20\n",
      "49000/49000 [==============================] - 5s 97us/step - loss: 1.2130 - acc: 0.5697 - val_loss: 1.3677 - val_acc: 0.5180\n",
      "Epoch 8/20\n",
      "49000/49000 [==============================] - 5s 97us/step - loss: 1.1814 - acc: 0.5822 - val_loss: 1.3946 - val_acc: 0.5220\n",
      "Epoch 9/20\n",
      "49000/49000 [==============================] - 5s 95us/step - loss: 1.1548 - acc: 0.5896 - val_loss: 1.3730 - val_acc: 0.5260\n",
      "Epoch 10/20\n",
      "49000/49000 [==============================] - 5s 97us/step - loss: 1.1308 - acc: 0.5992 - val_loss: 1.4475 - val_acc: 0.5070\n",
      "Epoch 11/20\n",
      "49000/49000 [==============================] - 5s 97us/step - loss: 1.1071 - acc: 0.6064 - val_loss: 1.4041 - val_acc: 0.5260\n",
      "Epoch 12/20\n",
      "49000/49000 [==============================] - 5s 97us/step - loss: 1.0856 - acc: 0.6134 - val_loss: 1.4449 - val_acc: 0.5220\n",
      "Epoch 13/20\n",
      "49000/49000 [==============================] - 5s 97us/step - loss: 1.0650 - acc: 0.6217 - val_loss: 1.4353 - val_acc: 0.5180\n",
      "Epoch 14/20\n",
      "49000/49000 [==============================] - 5s 97us/step - loss: 1.0463 - acc: 0.6261 - val_loss: 1.4812 - val_acc: 0.5080\n",
      "Epoch 15/20\n",
      "49000/49000 [==============================] - 5s 99us/step - loss: 1.0320 - acc: 0.6323 - val_loss: 1.4421 - val_acc: 0.5380\n",
      "Epoch 16/20\n",
      "49000/49000 [==============================] - 5s 97us/step - loss: 1.0112 - acc: 0.6387 - val_loss: 1.5151 - val_acc: 0.5140\n",
      "Epoch 17/20\n",
      "49000/49000 [==============================] - 5s 98us/step - loss: 0.9967 - acc: 0.6455 - val_loss: 1.4897 - val_acc: 0.5210\n",
      "Epoch 18/20\n",
      "49000/49000 [==============================] - 5s 100us/step - loss: 0.9809 - acc: 0.6489 - val_loss: 1.4775 - val_acc: 0.5300\n",
      "Epoch 19/20\n",
      "49000/49000 [==============================] - 5s 99us/step - loss: 0.9678 - acc: 0.6544 - val_loss: 1.4719 - val_acc: 0.5260\n",
      "Epoch 20/20\n",
      "49000/49000 [==============================] - 5s 99us/step - loss: 0.9564 - acc: 0.6582 - val_loss: 1.4915 - val_acc: 0.5330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fb8653dc88>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################################\n",
    "# TODO: Train your model using the training and validation data loaded at   #\n",
    "# the beginning of the exercise. Set 'verbose=1' to observe the progress.   #\n",
    "# Let it run for a few epochs, 10 is a good start that's still quick to run #\n",
    "# on a notebook cpu.                                                        #\n",
    "#############################################################################\n",
    "\n",
    "model.fit(X_train, y_train,epochs=20, verbose=1,batch_size = 32,validation_data=(X_val, y_val))\n",
    "\n",
    "#############################################################################\n",
    "#                         END OF YOUR CODE                                  #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Test your model: [3pt]\n",
    "\n",
    "You should achieve a classification accuracy of greater than 52% on the test set.\n",
    "Your precision depends on the choices you made earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 44us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.439913185119629, 0.532]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################################\n",
    "# TODO: Evaluate your model on the test set.                                #\n",
    "# Print loss and accuracy results                                           # \n",
    "#############################################################################\n",
    "\n",
    "model.evaluate(X_test, y_test, batch_size = 32)\n",
    "\n",
    "#############################################################################\n",
    "#                         END OF YOUR CODE                                  #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
