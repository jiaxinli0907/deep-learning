{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Programming Exercise 7: Convolutional Networks in Keras\n",
    "\n",
    "Welcome to the 7th assignment of deep learning programming!\n",
    "In this assignment you will implement a convolutional neural network in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import keras\n",
    "import h5py\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import *\n",
    "from utils.data_utils import load_CIFAR10\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We will use the same dataset as previous assignments. \n",
    "However, note the CNN input is different from that of traditional neural networks, it is width x height x channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 32, 32, 3)\n",
      "Train labels shape:  (49000, 10)\n",
      "Validation data shape:  (1000, 32, 32, 3)\n",
      "Validation labels shape:  (1000, 10)\n",
      "Test data shape:  (1000, 32, 32, 3)\n",
      "Test labels shape:  (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = '../../data/cifar'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Normalize the data\n",
    "    X_train /= 255\n",
    "    X_val /= 255\n",
    "    X_test /= 255\n",
    "    X_dev /= 255\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: build a model [10pt]\n",
    "\n",
    "This is an open assgiment, you should use whatever you have learnt in this course to build a promising model. For example, dropout, batch normalization, etc. After building model, you can call `model.summary()` to check architecture of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               36992     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 66,922\n",
      "Trainable params: 66,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "\n",
    "### START CODE HERE ###\n",
    "model = None\n",
    "\n",
    "model = Sequential()\n",
    "# setup first conv layer\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\",input_shape=input_shape, padding='same')) \n",
    "# setup second conv layer\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\",input_shape=input_shape, padding='same'))\n",
    "          \n",
    "# setup first maxpooling layer\n",
    "model.add(MaxPooling2D(pool_size=(3, 3))) \n",
    "\n",
    "# setup third conv layer\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\",padding='same'))  \n",
    "# setup forth conv layer\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\",padding='same'))  \n",
    "          \n",
    "# setup second maxpooling layer\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "# add flatten layer,\n",
    "model.add(Flatten())\n",
    "\n",
    "# add first full connection layer\n",
    "model.add(Dense(128, activation='relu')) \n",
    "\n",
    "# add dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# add second full connection layer\n",
    "model.add(Dense(10, activation='relu'))  \n",
    "\n",
    "\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: compile, train and test your model [2pt]\n",
    "\n",
    "After a number of epoches, you can achieve a much better performance than previous assginments. \n",
    "For example, our implementation has nearly 85% on valiation set and around 83% on test set.\n",
    "\n",
    "Hint: use `Callbacks` in Keras to keep the best model.\n",
    "\n",
    "Important: Store your model as model.hdf5 and upload it to the git repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               36992     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 66,922\n",
      "Trainable params: 66,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From F:\\software\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 49000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "49000/49000 [==============================] - 174s 4ms/step - loss: 0.3356 - acc: 0.8998 - val_loss: 0.2958 - val_acc: 0.8999\n",
      "Epoch 2/5\n",
      "49000/49000 [==============================] - 172s 4ms/step - loss: 0.3227 - acc: 0.8996 - val_loss: 0.3078 - val_acc: 0.9000\n",
      "Epoch 3/5\n",
      "49000/49000 [==============================] - 175s 4ms/step - loss: 0.3241 - acc: 0.8996 - val_loss: 0.3233 - val_acc: 0.9000\n",
      "Epoch 4/5\n",
      "49000/49000 [==============================] - 171s 3ms/step - loss: 0.3242 - acc: 0.9000 - val_loss: 0.3251 - val_acc: 0.9000\n",
      "Epoch 5/5\n",
      "49000/49000 [==============================] - 171s 3ms/step - loss: 0.3255 - acc: 0.9000 - val_loss: 0.3251 - val_acc: 0.9000\n",
      "Test loss: 0.3251143670082092\n",
      "Test accuracy: 0.8999999761581421\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "# if want to use SGD, first define sgd, then set optimizer=sgd\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0, nesterov=True)\n",
    "\n",
    "# select loss\\optimizer\\\n",
    "model.compile(loss='binary_crossentropy',optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# draw the model structure\n",
    "#plot_model(model, show_shapes=True,\n",
    " #          to_file=os.path.join(resultpath, 'model.png'))\n",
    "\n",
    "# input data to model and train\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=5,\n",
    "                        validation_data=(X_test, y_test), verbose=1, shuffle=True)\n",
    "\n",
    "# evaluate the model\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "    \n",
    "### END CODE HERE ###\n",
    "\n",
    "model.save('model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Description [3pt]\n",
    "\n",
    "Describe in just a few words what the inuition behind the layers types in your model is, why/how they improve the performance compared to vanilla cnns. Be specific about the performance metric: Improving accuracy is not the same as improving training speed. Be critical, point out drawbacks that you can think of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer here!\n",
    "\n",
    "Use a four layer CNN to slove the problem. The structure is conv layer 1 -> conv layer 2 -> max pooling 1 -> conv layer 3 -> conv layer 4 -> max pooling 2 -> flatten layer -> fully connected layer 1 -> dropout -> output.\n",
    "The more layers and nerons we use, the higher the accuracy. Comparing to vanilla cnns, out model is more complicated and use more layers and parameters to slove the problem. So it achieves a higher accuracy. But a too complicated model may lead to a huge increase in training time. So we choose the number of layers and parameters which are neither too huge nor too small. The drawback of my model may be that the dropout layer does not work. Based on the structure of this model, introducing more parameters will not improve accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
